# Captsone Project: Langague Analysis
## Overview
For any investment portfolios, diversification is the primary risk management tool.  For simple equity portfolios, diversification is usually measured using different discrete buckets--by market cap, geography, style factor or, most typically, sector/industry.  By weighting each stock (within an investment universe) such that these buckets are evenly distributed, you are theoretically protected from downturns affecting any single one of these buckets.

For those slightly more quantitatively-inclined, diversification can be measured by the pair-wise correlations between the individual stocks that make up the portfolio.  Stocks which are less correlated (positive or negative) can be favored for their supposed idiosyncratice stock movements while a stock with high positive correlation might be reduced or entirely cut from the portfolio as other stocks can provide the same factor exposure more effeciently.

These two metrics of diversification are often combined in the field of portfolio optimization.  With a correlation matrix and the expected returns for each stock, one can analytically solve for the weightings that will provide the highest expected return with the lowerst variance (mean-variance optimization).  The discrete classifications can be applied as an overlay such that an optimal risk-reward portfolio weighting is found while maintaining a target weighting for each discrete buckets.

However, there are important caveats to how well these two measures work for future diversification.  Sector/Industry categories are ultimately subjective and, despite dynamically changing industries and companies, rarely change assigned labels until economic realities require massive overhauling of the entire system.  On the other hand, using stock price correlations, by definition, mean the use of a backward-looking metric (rarely adjusted for time) that is influenced by market factors--such as investor sentiment--that have nothing to do with the underlying business(es).

The goal of this project is to consider an additional tool (not an alternative) that tries to address these caveats.  Through analysis of a company's annual (10k) risk disclosures, I hope to extract features that are forward-looking and closely related to the company's underlying fundamentals.  Besides being subject to the ability/desire to publicly identify potential risks, these features may also strike a balance between consistentcy and flexibility.  Furthermore, clustering techniques applied to these new features can produce both discrete bucketings (typical clustering) or contiounous metrics (especially, although not addressed in this project, through mixtures).

## Directory Guide
### Data Folder
In the data folder, there are five folders--Collections, Descriptions, Logs, Results & Samples.  There are also two excel files--one that contains a simple, working list of all the stocks included in this project ('TMT List.xlsx') and one with the same list with additional details added like fiscal year end, sec-designated names for each 10K, CIK (the key identifier for collecting SEC data) and a SIC classification ('TMT Universe Data.xlsx').

Collections and Descriptions are pretty self-explanatory:  within descriptions, there is a text file for each company in the dataset that has its sector, industry and overview/profile, per Yahoo Finance.  Collections contains stock groupings that were frequently needed--saving computational time--and vocab lists.

In the Samples folder, all the text files extracted from the company's Risk Disclosures are organized by ticker sign (with subfolders) and year (name of the individual text files).

In the Logs folder, there are three excel files that track the status of extraction for each risk disclosure in the project's dataset.  These were used primarily in the text extraction phase.  However, 'Filed.xlsx' and 'Paths.xlsx' is often used in the primary notebook to create groups (e.g. companies with risk disclosures going back at least five years) and indicate which text files were available and where to find them within this directory.  There are also text files within the logs folder which was needed to keep track of which extraction methodologies were attempted for a company and when.  This made it possible to keep track of errors exclusively attributable to an extraction attempt and when new methods were developed which ones to apply.

The Image folder contains the different correlation heatmaps and network designs as well as the dendograms created by different agglomerative clusterings.  The subfolder, Wordclouds, has the many images generated for each stock and a number of different groupings.  

The Results' folder contains various excel files for different classification attempts and text files for the dictionaries generated by different vectorizers.  
### Code Folder
The primary file in this folder is the 'Functionality.py' script.  This file contains all the functions, including those for scrapping/extraction, used in this project.  Inside the rough drafts folder are notebooks (some .py files) that were created for initial building and also experimental code.  Snippets from each were edited and copied into the final notebook.

## Scrapping 10Ks Methodology & Review
For each company, the SEC provides am accesible json file (indicated by the company's CIK number) that direct one to the appropriate directory name for any given filing.  The first step, after collecting the appropriate CIK identificaiton, was to filter out non-10-K paths.  The remaining paths gave access to the 10-K of interest in a semi-structured html format.  

This file was used to extract the Risk Disclosure prose which were then saved out to the Samples folder (described above).  However because the html structure was inconsistent across time and companies, different methodologies worked with different filings.  The primary difference in these methods were how the Risk Factor section was identified.  

For an example on how this was used practically, look in the Coding Rough Draft Folder for the notebook titled 'Scrapping'.


